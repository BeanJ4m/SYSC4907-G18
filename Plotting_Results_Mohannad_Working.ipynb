{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a01474e1",
   "metadata": {},
   "source": [
    "<font color='White'>***Libraries and Constants***</font>\n",
    "---\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ad3ba4d7-0489-464a-a4a3-4fa9196b1b7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from seaborn) (2.2.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "34e1429d-c81f-4d1f-9322-c97f4e526a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ROUNDS = 40 \n",
    "SPLITS = 1\n",
    "# Define a variable for the base path to use for all use cases\n",
    "PATH = \"DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups\"  # Change this to your desired path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce9748",
   "metadata": {},
   "source": [
    "<font color='Green'>***Metrics and Functions***</font>\n",
    "---\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cf430e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AUTO-DETECT CLASSCOUNT METRIC FUNCTIONS (DROP-IN SAFE)\n",
    "# ============================================================\n",
    "\n",
    "def calculate_accuracy(actual_values, predicted_values):\n",
    "    \"\"\"Fraction of correct predictions.\"\"\"\n",
    "    if len(actual_values) == 0:\n",
    "        return 0.0\n",
    "    return sum(a == p for a, p in zip(actual_values, predicted_values)) / len(actual_values)\n",
    "\n",
    "\n",
    "def _build_label_index(actual_values, predicted_values):\n",
    "    \"\"\"\n",
    "    Auto-detect all class labels and map them to 0..K-1.\n",
    "    This avoids IndexErrors and handles any label format.\n",
    "    \"\"\"\n",
    "    unique_labels = sorted(set(actual_values) | set(predicted_values))\n",
    "    label_to_idx = {lab: i for i, lab in enumerate(unique_labels)}\n",
    "    return unique_labels, label_to_idx\n",
    "\n",
    "\n",
    "def calculate_weighted_precision(actual_values, predicted_values, _unused_classcount=None):\n",
    "    if len(actual_values) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    labels, idx = _build_label_index(actual_values, predicted_values)\n",
    "    K = len(labels)\n",
    "\n",
    "    tp = [0] * K\n",
    "    fp = [0] * K\n",
    "    actual_count = [0] * K\n",
    "\n",
    "    for a, p in zip(actual_values, predicted_values):\n",
    "        ai = idx[a]\n",
    "        pi = idx[p]\n",
    "        actual_count[ai] += 1\n",
    "        if a == p:\n",
    "            tp[ai] += 1\n",
    "        else:\n",
    "            fp[pi] += 1\n",
    "\n",
    "    total = len(actual_values)\n",
    "    precision_sum = 0.0\n",
    "\n",
    "    for i in range(K):\n",
    "        denom = tp[i] + fp[i]\n",
    "        precision_i = tp[i] / denom if denom > 0 else 0.0\n",
    "        weight_i = actual_count[i] / total\n",
    "        precision_sum += precision_i * weight_i\n",
    "\n",
    "    return precision_sum\n",
    "\n",
    "\n",
    "def calculate_weighted_recall(actual_values, predicted_values, _unused_classcount=None):\n",
    "    if len(actual_values) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    labels, idx = _build_label_index(actual_values, predicted_values)\n",
    "    K = len(labels)\n",
    "\n",
    "    tp = [0] * K\n",
    "    fn = [0] * K\n",
    "    actual_count = [0] * K\n",
    "\n",
    "    for a, p in zip(actual_values, predicted_values):\n",
    "        ai = idx[a]\n",
    "        actual_count[ai] += 1\n",
    "        if a == p:\n",
    "            tp[ai] += 1\n",
    "        else:\n",
    "            fn[ai] += 1\n",
    "\n",
    "    total = len(actual_values)\n",
    "    recall_sum = 0.0\n",
    "\n",
    "    for i in range(K):\n",
    "        denom = tp[i] + fn[i]\n",
    "        recall_i = tp[i] / denom if denom > 0 else 0.0\n",
    "        weight_i = actual_count[i] / total\n",
    "        recall_sum += recall_i * weight_i\n",
    "\n",
    "    return recall_sum\n",
    "\n",
    "\n",
    "def calculate_weighted_f1(actual_values, predicted_values, _unused_classcount=None):\n",
    "    if len(actual_values) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    labels, idx = _build_label_index(actual_values, predicted_values)\n",
    "    K = len(labels)\n",
    "\n",
    "    tp = [0] * K\n",
    "    fp = [0] * K\n",
    "    fn = [0] * K\n",
    "\n",
    "    for a, p in zip(actual_values, predicted_values):\n",
    "        ai = idx[a]\n",
    "        pi = idx[p]\n",
    "        if a == p:\n",
    "            tp[ai] += 1\n",
    "        else:\n",
    "            fp[pi] += 1\n",
    "            fn[ai] += 1\n",
    "\n",
    "    total = len(actual_values)\n",
    "    f1_sum = 0.0\n",
    "\n",
    "    for i in range(K):\n",
    "        prec_i = tp[i] / (tp[i] + fp[i]) if (tp[i] + fp[i]) > 0 else 0.0\n",
    "        rec_i  = tp[i] / (tp[i] + fn[i]) if (tp[i] + fn[i]) > 0 else 0.0\n",
    "\n",
    "        f1_i = (2 * prec_i * rec_i / (prec_i + rec_i)) if (prec_i + rec_i) > 0 else 0.0\n",
    "\n",
    "        weight_i = (tp[i] + fn[i]) / total\n",
    "        f1_sum += f1_i * weight_i\n",
    "\n",
    "    return f1_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ea905ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_values(values_list):\n",
    "    return [value if value >= 0.5 else 0.5 for value in values_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d25dd4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_list(values_list):\n",
    "    while len(values_list) < ROUNDS:\n",
    "        values_list.append(values_list[-1])\n",
    "    return values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3db4a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_report(actual, predicted, class_labels=None):\n",
    "    if class_labels is None:\n",
    "        class_labels = sorted(set(actual) | set(predicted))\n",
    "    report = classification_report(actual, predicted, target_names=[str(label) for label in class_labels])\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "965c2014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_classification_report(actual, predicted, file_path, class_labels=None):\n",
    "    if class_labels is None:\n",
    "        class_labels = sorted(set(actual) | set(predicted))\n",
    "    report = classification_report(actual, predicted, target_names=[str(label) for label in class_labels])\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(\"Classification Report:\\n\\n\")\n",
    "        file.write(report)\n",
    "    print(f\"Classification report saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fb979e",
   "metadata": {},
   "source": [
    "<font color='Orange'>***Confusion Matrix***</font>\n",
    "---\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b368f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label_names = ['Normal', 'DDoS_UDP', 'DDoS_ICMP', 'DDoS_TCP', 'DDoS_HTTP', 'Password', 'Vulnerability_scanner', 'SQL_injection']#, 'Uploading', 'Backdoor', 'Port_Scanning', 'XSS', 'Ransomware', 'MITM', 'OS_Fingerprinting']\n",
    "Label_numbers = [0, 1, 2, 3, 4, 5, 6, 7]#, 8, 9, 10, 11, 12, 13, 14]\n",
    "\n",
    "def plot_confusion_matrix_with_names(actual, predicted, label_numbers, label_names, title=\"Confusion Matrix\"):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix with label names instead of numbers.\n",
    "\n",
    "    Args:\n",
    "        actual (list): The list of actual class labels.\n",
    "        predicted (list): The list of predicted class labels.\n",
    "        label_numbers (list): The list of numeric label identifiers.\n",
    "        label_names (list): The corresponding list of label names.\n",
    "        title (str): The title of the confusion matrix plot.\n",
    "    \"\"\"\n",
    "    # Map numeric labels to their names\n",
    "    label_map = dict(zip(label_numbers, label_names))\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(actual, predicted, labels=label_numbers)\n",
    "    \n",
    "    # Replace numeric labels with names for the axes\n",
    "    class_labels = [label_map[num] for num in label_numbers]\n",
    "    \n",
    "    # Create a heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='magma', xticklabels=class_labels, yticklabels=class_labels)\n",
    "    \n",
    "    # Add labels, title, and a color bar\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"Actual Labels\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "58d9e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_confusion_matrix_with_names(Data[\"Perfect Post-Detection\"][\"Actual\"][160], Data[\"Perfect Post-Detection\"][\"Predictions\"][160], \n",
    "#                                  Label_numbers, Label_names, title=\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcc67a4",
   "metadata": {},
   "source": [
    "<font color='Red'>***Calculating and Saving Results***</font>\n",
    "---\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "af40fcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Centralized': {'Actual': {},\n",
      "                 'Path': 'DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups',\n",
      "                 'Predictions': {}}}\n"
     ]
    }
   ],
   "source": [
    "Data = {}\n",
    "Data[\"Centralized\"] = {}\n",
    "Data[\"Centralized\"][\"Path\"] = PATH  # Your centralized model output directory\n",
    "Data[\"Centralized\"][\"Actual\"] = {}\n",
    "Data[\"Centralized\"][\"Predictions\"] = {}\n",
    "# Data[\"Perfect Post-Detection\"] = {}\n",
    "# Data[\"Confidence Thresholding-Round 4\"] = {}\n",
    "# Data[\"Outlier Removing-Round 4\"] = {}\n",
    "# Data[\"No Post-Detection-Round 4\"] = {}\n",
    "# Data[\"Confidence Thresholding-Round 10\"] = {}\n",
    "# Data[\"Outlier Removing-Round 10\"] = {}\n",
    "# Data[\"No Post-Detection-Round 10\"] = {}\n",
    "# Data[\"Perfect Post-Detection\"]['Path'] = \"Ideal_20250206\"\n",
    "# Data[\"Confidence Thresholding-Round 4\"]['Path'] = \"Confidence_20250214_4\"\n",
    "# Data[\"Outlier Removing-Round 4\"]['Path'] = \"Outlier_20250214_4\"\n",
    "# Data[\"No Post-Detection-Round 4\"]['Path'] = \"NoPD_20250214_4\"\n",
    "# Data[\"Confidence Thresholding-Round 10\"]['Path'] = \"Confidence_20250214_10\"\n",
    "# Data[\"Outlier Removing-Round 10\"]['Path'] = \"Outlier_20250214_10\"\n",
    "# Data[\"No Post-Detection-Round 10\"]['Path'] = \"NoPD_20250214_10\"\n",
    "for Usecase in Data:\n",
    "    Data[Usecase]['Actual'] = {}\n",
    "    Data[Usecase]['Predictions'] = {}\n",
    "pprint.pprint(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a07de356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_1_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_2_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_3_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_4_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_5_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_6_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_7_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_8_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_9_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_10_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_11_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_12_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_13_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_14_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_15_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_16_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_17_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_18_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_19_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_20_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_21_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_22_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_23_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_24_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_25_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_26_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_27_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_28_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_29_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_30_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_31_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_32_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_33_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_34_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_35_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_36_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_37_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_38_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_39_actual\n",
      "File not found: DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/Global_40_actual\n"
     ]
    }
   ],
   "source": [
    "for Usecase in Data:\n",
    "    for i in range(1, ROUNDS*SPLITS+1):\n",
    "        try:\n",
    "            filename = f\"{Data[Usecase]['Path']}/Global_{i}_actual\"\n",
    "            with open(filename, 'rb') as file:\n",
    "                Actual = pickle.load(file)\n",
    "            Data[Usecase]['Actual'][i] = [item for sublist in Actual for item in sublist]\n",
    "            filename = f\"{Data[Usecase]['Path']}/Global_{i}_pred\"\n",
    "            with open(filename, 'rb') as file:\n",
    "                Pred = pickle.load(file)\n",
    "            Data[Usecase]['Predictions'][i] = [item for sublist in Pred for item in sublist]\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing file {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "440714d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# value_counts = Counter(Data['Confidence Thresholding']['Predictions'][160])\n",
    "# for value, count in value_counts.items():\n",
    "#     print(f\"Value: {value}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f9f8459b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Centralized': {'Accuracy': [], 'F1_Score': [], 'Precision': [], 'Recall': []}}\n"
     ]
    }
   ],
   "source": [
    "Results = {}\n",
    "for Usecase in Data:\n",
    "    Results[Usecase] = {}\n",
    "for Usecase in Results:\n",
    "    Results[Usecase]['Accuracy'] = []\n",
    "    Results[Usecase]['Recall'] = []\n",
    "    Results[Usecase]['Precision'] = [] \n",
    "    Results[Usecase]['F1_Score'] = []\n",
    "pprint.pprint(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a094c2be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usecase: Centralized Round: 1\n",
      "Usecase: Centralized Round: 2\n",
      "Usecase: Centralized Round: 3\n",
      "Usecase: Centralized Round: 4\n",
      "Usecase: Centralized Round: 5\n",
      "Usecase: Centralized Round: 6\n",
      "Usecase: Centralized Round: 7\n",
      "Usecase: Centralized Round: 8\n",
      "Usecase: Centralized Round: 9\n",
      "Usecase: Centralized Round: 10\n",
      "Usecase: Centralized Round: 11\n",
      "Usecase: Centralized Round: 12\n",
      "Usecase: Centralized Round: 13\n",
      "Usecase: Centralized Round: 14\n",
      "Usecase: Centralized Round: 15\n",
      "Usecase: Centralized Round: 16\n",
      "Usecase: Centralized Round: 17\n",
      "Usecase: Centralized Round: 18\n",
      "Usecase: Centralized Round: 19\n",
      "Usecase: Centralized Round: 20\n",
      "Usecase: Centralized Round: 21\n",
      "Usecase: Centralized Round: 22\n",
      "Usecase: Centralized Round: 23\n",
      "Usecase: Centralized Round: 24\n",
      "Usecase: Centralized Round: 25\n",
      "Usecase: Centralized Round: 26\n",
      "Usecase: Centralized Round: 27\n",
      "Usecase: Centralized Round: 28\n",
      "Usecase: Centralized Round: 29\n",
      "Usecase: Centralized Round: 30\n",
      "Usecase: Centralized Round: 31\n",
      "Usecase: Centralized Round: 32\n",
      "Usecase: Centralized Round: 33\n",
      "Usecase: Centralized Round: 34\n",
      "Usecase: Centralized Round: 35\n",
      "Usecase: Centralized Round: 36\n",
      "Usecase: Centralized Round: 37\n",
      "Usecase: Centralized Round: 38\n",
      "Usecase: Centralized Round: 39\n",
      "Usecase: Centralized Round: 40\n"
     ]
    }
   ],
   "source": [
    "for Usecase in Results:\n",
    "    for Round in range(1, ROUNDS*SPLITS+1):\n",
    "        try:\n",
    "            Results[Usecase]['Accuracy'].append(calculate_accuracy(Data[Usecase]['Actual'][Round], Data[Usecase]['Predictions'][Round]))\n",
    "            Results[Usecase]['Precision'].append(calculate_weighted_precision(Data[Usecase]['Actual'][Round], Data[Usecase]['Predictions'][Round], CLASS_COUNT))\n",
    "            Results[Usecase]['Recall'].append(calculate_weighted_recall(Data[Usecase]['Actual'][Round], Data[Usecase]['Predictions'][Round], CLASS_COUNT))\n",
    "            Results[Usecase]['F1_Score'].append(calculate_weighted_f1(Data[Usecase]['Actual'][Round], Data[Usecase]['Predictions'][Round], CLASS_COUNT))\n",
    "        except KeyError:\n",
    "            print('Usecase:', Usecase, 'Round:', Round)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b32df4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Usecase in Results:\n",
    "#     Results[Usecase]['Accuracy'] = update_values(Results[Usecase]['Accuracy'])\n",
    "#     Results[Usecase]['Recall'] = update_values(Results[Usecase]['Recall'])\n",
    "#     Results[Usecase]['Precision'] = update_values(Results[Usecase]['Precision'])    \n",
    "#     Results[Usecase]['F1_Score'] = update_values(Results[Usecase]['F1_Score'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f56712c",
   "metadata": {},
   "source": [
    "<font color='Light Blue'>***Save/ Load Calculated Results***</font>\n",
    "---\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4a866d11-6b4a-4bec-9630-d3454ef24489",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/PD_Results.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mPATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/PD_Results.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      2\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(Results, file)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/IPython/core/interactiveshell.py:308\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'DNNCent5atk_40_rounds_1_clients_3_epochs_64_batch_0.0025_lr_120_data_groups/PD_Results.pkl'"
     ]
    }
   ],
   "source": [
    "with open(f\"{PATH}/PD_Results.pkl\", \"wb\") as file:\n",
    "    pickle.dump(Results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8befbcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"PD_Results.pkl\", \"rb\") as file:\n",
    "#     Results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c9984",
   "metadata": {},
   "source": [
    "<font color='Green'>***Plotting Results***</font>\n",
    "---\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd732d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "LineStyle = ['ro-', 'b*-', 'ks-', 'gh-', 'm<-', 'yp-', 'b*-', 'gh-', 'rH-', 'c+-', 'mx-', 'ro-', 'b*-', 'ks-', 'gh-', 'y<-']\n",
    "fig = plt.figure(figsize=(17.2, 13), dpi=450)\n",
    "axx = fig.add_subplot(1,1,1)\n",
    "# plt.figure(dpi=1000)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "\n",
    "x_axis = np.array(np.arange(1, ROUNDS+1, 1).tolist())\n",
    "x_axis = np.insert(x_axis, 0, 0)\n",
    "y_points = {}\n",
    "for Usecase in Data:\n",
    "    y_points[Usecase] = np.array(Results[Usecase]['Accuracy'])\n",
    "    y_points[Usecase] = np.insert(y_points[Usecase], 0, 0.5)\n",
    "index = 0\n",
    "for Usecase in Data:\n",
    "    axx.plot(x_axis, y_points[Usecase],LineStyle[index], label = Usecase, linewidth=2.5,  markersize=10)\n",
    "    index += 1\n",
    "    \n",
    "axx.set_xlabel(f'{PATH}', fontdict={'fontsize': 36})\n",
    "axx.set_ylabel('Detection Accuracy', fontdict={'fontsize': 36})\n",
    "axx.set_xticks(np.arange(0, ROUNDS+1, 5).tolist()) \n",
    "axx.set_yticks(np.arange(0.30, 1.05, 0.05).tolist())\n",
    "axx.legend(loc = 'lower right', prop={'size': 16})\n",
    "axx.tick_params(axis='x', which='both', bottom=True, top=True, labelbottom=True, labeltop=True, labelsize=20, colors='black')\n",
    "axx.xaxis.set_ticks_position('both')\n",
    "axx.tick_params(axis='y', which='both', left=True, right=True, labelleft=True, labelright=True, labelsize=20, colors='black')\n",
    "axx.yaxis.set_ticks_position('both')\n",
    "axx.xaxis.label.set_color('black')\n",
    "axx.yaxis.label.set_color('black')\n",
    "fig.savefig(f\"{PATH}/1_Accuracy.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f13e63-48da-4c9b-9456-7b32b5c3a430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 6400x4800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "LineStyle = ['ro-', 'b*-', 'ks-', 'gh-', 'm<-', 'yp-', 'b*-', 'gh-', 'rH-', 'c+-', 'mx-', 'ro-', 'b*-', 'ks-', 'gh-', 'y<-']\n",
    "fig = plt.figure(figsize=(17.2, 13), dpi=450)\n",
    "axx = fig.add_subplot(1,1,1)\n",
    "plt.figure(dpi=1000)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "\n",
    "x_axis = np.array(np.arange(1, ROUNDS+1, 1).tolist())\n",
    "x_axis = np.insert(x_axis, 0, 0)\n",
    "y_points = {}\n",
    "for Usecase in Data:\n",
    "    y_points[Usecase] = np.array(Results[Usecase]['Recall'])\n",
    "    y_points[Usecase] = np.insert(y_points[Usecase], 0, 0.5)\n",
    "\n",
    "index = 0\n",
    "for Usecase in Data:\n",
    "    axx.plot(x_axis, y_points[Usecase],LineStyle[index], label = Usecase, linewidth=2.5,  markersize=10)\n",
    "    index += 1\n",
    "    \n",
    "axx.set_xlabel(f'{PATH}', fontdict={'fontsize': 36})\n",
    "axx.set_ylabel('Detection Recall', fontdict={'fontsize': 36})\n",
    "axx.set_xticks(np.arange(0, ROUNDS+1, 5).tolist()) \n",
    "axx.set_yticks(np.arange(0.30, 1.05, 0.05).tolist())\n",
    "axx.legend(loc = 'lower right', prop={'size': 16})\n",
    "axx.tick_params(axis='x', which='both', bottom=True, top=True, labelbottom=True, labeltop=True, labelsize=20, colors='black')\n",
    "axx.xaxis.set_ticks_position('both')\n",
    "axx.tick_params(axis='y', which='both', left=True, right=True, labelleft=True, labelright=True, labelsize=20, colors='black')\n",
    "axx.yaxis.set_ticks_position('both')\n",
    "axx.xaxis.label.set_color('black')\n",
    "axx.yaxis.label.set_color('black')\n",
    "fig.savefig(f\"{PATH}/1_Wieghted_Recall.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9813c1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 6400x4800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "LineStyle = ['ro-', 'b*-', 'ks-', 'gh-', 'm<-', 'yp-', 'b*-', 'gh-', 'rH-', 'c+-', 'mx-', 'ro-', 'b*-', 'ks-', 'gh-', 'y<-']\n",
    "fig = plt.figure(figsize=(17.2, 13), dpi=450)\n",
    "axx = fig.add_subplot(1,1,1)\n",
    "plt.figure(dpi=1000)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "\n",
    "x_axis = np.array(np.arange(1, ROUNDS+1, 1).tolist())\n",
    "x_axis = np.insert(x_axis, 0, 0)\n",
    "y_points = {}\n",
    "for Usecase in Data:\n",
    "    y_points[Usecase] = np.array(Results[Usecase]['Precision'])\n",
    "    y_points[Usecase] = np.insert(y_points[Usecase], 0, 0.5)\n",
    "\n",
    "index = 0\n",
    "for Usecase in Data:\n",
    "    axx.plot(x_axis, y_points[Usecase],LineStyle[index], label = Usecase, linewidth=2.5,  markersize=10)\n",
    "    index += 1\n",
    "    \n",
    "axx.set_xlabel(f'{PATH}', fontdict={'fontsize': 36})\n",
    "axx.set_ylabel('Detection Precision', fontdict={'fontsize': 36})\n",
    "axx.set_xticks(np.arange(0, ROUNDS+1, 5).tolist()) \n",
    "axx.set_yticks(np.arange(0.30, 1.05, 0.05).tolist())\n",
    "axx.legend(loc = 'lower right', prop={'size': 16})\n",
    "axx.tick_params(axis='x', which='both', bottom=True, top=True, labelbottom=True, labeltop=True, labelsize=20, colors='black')\n",
    "axx.xaxis.set_ticks_position('both')\n",
    "axx.tick_params(axis='y', which='both', left=True, right=True, labelleft=True, labelright=True, labelsize=20, colors='black')\n",
    "axx.yaxis.set_ticks_position('both')\n",
    "axx.xaxis.label.set_color('black')\n",
    "axx.yaxis.label.set_color('black')\n",
    "fig.savefig(f\"{PATH}/1_Wieghted_Precision.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5eaf68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 6400x4800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "LineStyle = ['ro-', 'b*-', 'ks-', 'gh-', 'm<-', 'yp-', 'b*-', 'gh-', 'rH-', 'c+-', 'mx-', 'ro-', 'b*-', 'ks-', 'gh-', 'y<-']\n",
    "fig = plt.figure(figsize=(17.2, 13), dpi=450)\n",
    "axx = fig.add_subplot(1,1,1)\n",
    "plt.figure(dpi=1000)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "\n",
    "x_axis = np.array(np.arange(1, ROUNDS+1, 1).tolist())\n",
    "x_axis = np.insert(x_axis, 0, 0)\n",
    "y_points = {}\n",
    "for Usecase in Data:\n",
    "    y_points[Usecase] = np.array(Results[Usecase]['F1_Score'])\n",
    "    y_points[Usecase] = np.insert(y_points[Usecase], 0, 0.5)\n",
    "\n",
    "index = 0\n",
    "for Usecase in Data:\n",
    "    axx.plot(x_axis, y_points[Usecase],LineStyle[index], label = Usecase, linewidth=2.5,  markersize=10)\n",
    "    index += 1\n",
    "    \n",
    "axx.set_xlabel(f'{PATH}', fontdict={'fontsize': 36})\n",
    "axx.set_ylabel('Detection F1_Score', fontdict={'fontsize': 36})\n",
    "axx.set_xticks(np.arange(0, ROUNDS+1, 5).tolist()) \n",
    "axx.set_yticks(np.arange(0.30, 1.05, 0.05).tolist())\n",
    "axx.legend(loc = 'lower right', prop={'size': 16})\n",
    "axx.tick_params(axis='x', which='both', bottom=True, top=True, labelbottom=True, labeltop=True, labelsize=20, colors='black')\n",
    "axx.xaxis.set_ticks_position('both')\n",
    "axx.tick_params(axis='y', which='both', left=True, right=True, labelleft=True, labelright=True, labelsize=20, colors='black')\n",
    "axx.yaxis.set_ticks_position('both')\n",
    "axx.xaxis.label.set_color('black')\n",
    "axx.yaxis.label.set_color('black')\n",
    "fig.savefig(f\"{PATH}/1_Wieghted_F1_Score.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.close(fig) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
